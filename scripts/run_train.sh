#!/bin/bash

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

# è„šæœ¬é…ç½®
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
MODEL_PATH="/root/autodl-tmp/Federated_learning/llm_init_ckpt/Qwen2.5-0.5B-Instruct"
DATA_DIR="$PROJECT_DIR/data/enhanced_qwen"
OUTPUT_DIR="$PROJECT_DIR/federated_qwen_output"
# DATA_DIR="$PROJECT_DIR/data/debug_qwen"
# OUTPUT_DIR="$PROJECT_DIR/debug_qwen_output"
EPOCHS=1
LEARNING_RATE=2e-6
BATCH_SIZE=8  # æå‡åˆ°4ï¼Œæ›´å¥½åˆ©ç”¨GPU
GRADIENT_ACCUMULATION_STEPS=2  # æ¢¯åº¦ç´¯ç§¯ï¼Œç­‰æ•ˆbatch_size=8
MAX_LENGTH=2048
SAVE_STEPS=200  # å‡å°‘ä¿å­˜é¢‘ç‡ï¼Œå› ä¸ºæœ‰æ•ˆbatchæ›´å¤§äº†
MAX_SAMPLES="10000"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    echo "è”é‚¦å­¦ä¹ æ¨¡å‹è®­ç»ƒè„šæœ¬"
    echo ""
    echo "ç”¨æ³•: $0 [é€‰é¡¹]"
    echo ""
    echo "é€‰é¡¹:"
    echo "  -m, --model-path PATH     é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ (é»˜è®¤: $MODEL_PATH)"
    echo "  -d, --data-dir DIR        æ•°æ®ç›®å½• (é»˜è®¤: $DATA_DIR)"
    echo "  -o, --output-dir DIR      è¾“å‡ºç›®å½• (é»˜è®¤: $OUTPUT_DIR)"
    echo "  -e, --epochs N           è®­ç»ƒè½®æ•° (é»˜è®¤: $EPOCHS)"
    echo "  -lr, --learning-rate LR   å­¦ä¹ ç‡ (é»˜è®¤: $LEARNING_RATE)"
    echo "  -b, --batch-size N       æ‰¹æ¬¡å¤§å° (é»˜è®¤: $BATCH_SIZE)"
    echo "  --grad-accum N           æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (é»˜è®¤: $GRADIENT_ACCUMULATION_STEPS)"
    echo "  -l, --max-length N       æœ€å¤§åºåˆ—é•¿åº¦ (é»˜è®¤: $MAX_LENGTH)"
    echo "  -s, --save-steps N       ä¿å­˜é—´éš” (é»˜è®¤: $SAVE_STEPS)"
    echo "  --max_samples N          æœ€å¤§æ ·æœ¬æ•° (ç”¨äºæµ‹è¯•)"
    echo "  --quick                  å¿«é€Ÿè®­ç»ƒæ¨¡å¼ (1è½®ï¼Œ100æ ·æœ¬)"
    echo "  --full                   å®Œæ•´è®­ç»ƒæ¨¡å¼ (5è½®ï¼Œæ‰€æœ‰æ ·æœ¬)"
    echo "  -h, --help              æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
    echo ""
    echo "é¢„è®¾æ¨¡å¼:"
    echo "  --quick: å¿«é€Ÿæµ‹è¯•è®­ç»ƒ (1è½®ï¼Œ100æ ·æœ¬ï¼Œå­¦ä¹ ç‡5e-6)"
    echo "  --full:  å®Œæ•´æ­£å¼è®­ç»ƒ (5è½®ï¼Œæ‰€æœ‰æ ·æœ¬ï¼Œå­¦ä¹ ç‡1e-6)"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0                                    # ä½¿ç”¨é»˜è®¤å‚æ•°"
    echo "  $0 --quick                           # å¿«é€Ÿæµ‹è¯•æ¨¡å¼"
    echo "  $0 --full                            # å®Œæ•´è®­ç»ƒæ¨¡å¼"
    echo "  $0 -e 5 -lr 1e-6                    # è‡ªå®šä¹‰å‚æ•°"
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        -m|--model-path)
            MODEL_PATH="$2"
            shift 2
            ;;
        -d|--data-dir)
            DATA_DIR="$2"
            shift 2
            ;;
        -o|--output-dir)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        -e|--epochs)
            EPOCHS="$2"
            shift 2
            ;;
        -lr|--learning-rate)
            LEARNING_RATE="$2"
            shift 2
            ;;
        -b|--batch-size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --grad-accum)
            GRADIENT_ACCUMULATION_STEPS="$2"
            shift 2
            ;;
        -l|--max-length)
            MAX_LENGTH="$2"
            shift 2
            ;;
        -s|--save-steps)
            SAVE_STEPS="$2"
            shift 2
            ;;
        --max_samples)
            MAX_SAMPLES="$2"
            shift 2
            ;;
        --quick)
            EPOCHS=1
            LEARNING_RATE=5e-6
            BATCH_SIZE=2  # å¿«é€Ÿæ¨¡å¼ç”¨è¾ƒå°batch
            GRADIENT_ACCUMULATION_STEPS=1
            MAX_SAMPLES=100
            SAVE_STEPS=50
            OUTPUT_DIR="$PROJECT_DIR/quick_train_output"
            log_info "ğŸš€ å¯ç”¨å¿«é€Ÿè®­ç»ƒæ¨¡å¼"
            shift
            ;;
        --full)
            EPOCHS=5
            LEARNING_RATE=1e-6
            BATCH_SIZE=8  # å®Œæ•´æ¨¡å¼ç”¨æ›´å¤§batch
            GRADIENT_ACCUMULATION_STEPS=2  # ç­‰æ•ˆbatch_size=16
            MAX_SAMPLES=""
            SAVE_STEPS=500
            OUTPUT_DIR="$PROJECT_DIR/full_train_output"
            log_info "ğŸ å¯ç”¨å®Œæ•´è®­ç»ƒæ¨¡å¼"
            shift
            ;;
        -h|--help)
            show_help
            exit 0
            ;;
        *)
            log_error "æœªçŸ¥å‚æ•°: $1"
            show_help
            exit 1
            ;;
    esac
done

# æ£€æŸ¥GPUå¯ç”¨æ€§
check_gpu() {
    if command -v nvidia-smi &> /dev/null; then
        gpu_info=$(nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits | head -1)
        log_success "ğŸ® GPUå¯ç”¨: $gpu_info"
        
        # æ£€æŸ¥GPUå†…å­˜
        free_memory=$(echo "$gpu_info" | cut -d',' -f3 | tr -d ' ')
        if [[ $free_memory -lt 8000 ]]; then
            log_warning "âš ï¸  GPUå†…å­˜ä¸è¶³8GBï¼Œå»ºè®®é‡Šæ”¾å†…å­˜æˆ–ä½¿ç”¨CPUè®­ç»ƒ"
        fi
    else
        log_warning "âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰"
    fi
}

# ä¸»å‡½æ•°
main() {
    log_info "ğŸš€ å¼€å§‹è”é‚¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ..."
    echo "=========================================="
    log_info "é…ç½®å‚æ•°:"
    log_info "  - æ¨¡å‹è·¯å¾„: $MODEL_PATH"
    log_info "  - æ•°æ®ç›®å½•: $DATA_DIR"
    log_info "  - è¾“å‡ºç›®å½•: $OUTPUT_DIR"
    log_info "  - è®­ç»ƒè½®æ•°: $EPOCHS"
    log_info "  - å­¦ä¹ ç‡: $LEARNING_RATE"
    log_info "  - æ‰¹æ¬¡å¤§å°: $BATCH_SIZE"
    log_info "  - æ¢¯åº¦ç´¯ç§¯: $GRADIENT_ACCUMULATION_STEPS æ­¥ (æœ‰æ•ˆbatch: $((BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS)))"
    log_info "  - æœ€å¤§é•¿åº¦: $MAX_LENGTH"
    log_info "  - ä¿å­˜é—´éš”: $SAVE_STEPS"
    if [[ -n "$MAX_SAMPLES" ]]; then
        log_info "  - æœ€å¤§æ ·æœ¬æ•°: $MAX_SAMPLES"
    fi
    echo "=========================================="

    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if [[ ! -d "$MODEL_PATH" ]]; then
        log_error "é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: $MODEL_PATH"
        exit 1
    fi

    # æ£€æŸ¥æ•°æ®ç›®å½•å’Œæ–‡ä»¶ - æ”¯æŒå¢å¼ºç‰ˆå’Œæ—§ç‰ˆæ•°æ®
    TRAIN_FILE_ENHANCED="$DATA_DIR/enhanced_qwen_train.jsonl"
    TRAIN_FILE_OLD="$DATA_DIR/qwen_processed/qwen_federated_train.jsonl"
    
    if [[ -f "$TRAIN_FILE_ENHANCED" ]]; then
        log_success "âœ“ å‘ç°å¢å¼ºç‰ˆè®­ç»ƒæ•°æ®: enhanced_qwen_train.jsonl"
    elif [[ -f "$TRAIN_FILE_OLD" ]]; then
        log_success "âœ“ å‘ç°æ—§ç‰ˆè®­ç»ƒæ•°æ®: qwen_processed/qwen_federated_train.jsonl"
    else
        log_error "è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€:"
        log_error "  - $TRAIN_FILE_ENHANCED (å¢å¼ºç‰ˆ)"
        log_error "  - $TRAIN_FILE_OLD (æ—§ç‰ˆ)"
        log_info "è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†: bash scripts/preprocess_data.sh"
        exit 1
    fi

    # æ£€æŸ¥GPU
    check_gpu

    # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
    cd "$PROJECT_DIR"

    # æ£€æŸ¥Pythonç¯å¢ƒ
    if ! command -v python &> /dev/null; then
        log_error "Pythonæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­"
        exit 1
    fi

    # æ£€æŸ¥è®­ç»ƒè„šæœ¬
    if [[ ! -f "train.py" ]]; then
        log_error "è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: train.py"
        exit 1
    fi

    # åˆ›å»ºè¾“å‡ºç›®å½•
    mkdir -p "$OUTPUT_DIR"

    # æ„å»ºè®­ç»ƒå‘½ä»¤
    train_cmd="python train.py \
        --data_dir \"$DATA_DIR\" \
        --model_path \"$MODEL_PATH\" \
        --epochs $EPOCHS \
        --learning_rate $LEARNING_RATE \
        --batch_size $BATCH_SIZE \
        --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
        --max_length $MAX_LENGTH \
        --save_steps $SAVE_STEPS \
        --output_dir \"$OUTPUT_DIR\""

    if [[ -n "$MAX_SAMPLES" ]]; then
        train_cmd="$train_cmd --max_samples $MAX_SAMPLES"
    fi

    # æ˜¾ç¤ºè®­ç»ƒæ•°æ®ä¿¡æ¯
    if [[ -f "$TRAIN_FILE_ENHANCED" ]]; then
        file_size=$(du -h "$TRAIN_FILE_ENHANCED" | cut -f1)
        line_count=$(wc -l < "$TRAIN_FILE_ENHANCED")
        log_info "ğŸ“Š å¢å¼ºç‰ˆè®­ç»ƒæ•°æ®: $line_count ä¸ªæ ·æœ¬ ($file_size)"
    elif [[ -f "$TRAIN_FILE_OLD" ]]; then
        file_size=$(du -h "$TRAIN_FILE_OLD" | cut -f1)
        line_count=$(wc -l < "$TRAIN_FILE_OLD")
        log_info "ğŸ“Š æ—§ç‰ˆè®­ç»ƒæ•°æ®: $line_count ä¸ªæ ·æœ¬ ($file_size)"
    fi

    # æ‰§è¡Œè®­ç»ƒ
    log_info "ğŸ”¥ å¼€å§‹æ¨¡å‹è®­ç»ƒ..."
    log_info "ğŸ’¡ å‘½ä»¤: $train_cmd"
    echo "=========================================="
    
    eval $train_cmd

    if [[ $? -eq 0 ]]; then
        log_success "ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼"
        
        # æ˜¾ç¤ºç»“æœä¿¡æ¯
        if [[ -f "$OUTPUT_DIR/federated_qwen_model.pth" ]]; then
            model_size=$(du -h "$OUTPUT_DIR/federated_qwen_model.pth" | cut -f1)
            log_success "æ¨¡å‹æ–‡ä»¶: $OUTPUT_DIR/federated_qwen_model.pth ($model_size)"
        fi
        
        if [[ -f "$OUTPUT_DIR/training_config.json" ]]; then
            log_success "è®­ç»ƒé…ç½®: $OUTPUT_DIR/training_config.json"
        fi
        
        echo "=========================================="
        log_info "âœ… è®­ç»ƒå®Œæˆï¼Œå¯ä»¥å¼€å§‹è¯„ä¼°ï¼š"
        log_info "   bash scripts/run_eval.sh --checkpoint_path \"$OUTPUT_DIR/federated_qwen_model.pth\""
        echo "=========================================="
    else
        log_error "âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼"
        exit 1
    fi
}

# è¿è¡Œä¸»å‡½æ•°
main "$@"
