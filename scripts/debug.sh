#!/bin/bash

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

# è„šæœ¬é…ç½®
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"

# éªŒè¯é…ç½®
SAMPLE_SIZE=100
TRAIN_RATIO=0.8  # 80æ¡è®­ç»ƒï¼Œ20æ¡æµ‹è¯•
RAILWAY_RATIO=0.6  # 60%é“è·¯è¿è¾“
EPOCHS=3
LEARNING_RATE=5e-6
BATCH_SIZE=2
GRADIENT_ACCUMULATION_STEPS=1
MAX_LENGTH=1024

# ç›®å½•é…ç½®
DEBUG_DATA_DIR="$PROJECT_DIR/data/debug_validation"
DEBUG_OUTPUT_DIR="$PROJECT_DIR/debug_validation_output"

# é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_step() {
    echo -e "${PURPLE}[STEP]${NC} $1"
}

# æ˜¾ç¤ºé…ç½®ä¿¡æ¯
show_config() {
    echo -e "${BLUE}ğŸ”§ è”é‚¦å­¦ä¹ æ¨¡å‹éªŒè¯é…ç½®${NC}"
    echo "=========================================="
    echo "ğŸ“Š æ•°æ®é…ç½®:"
    echo "  - æ€»æ ·æœ¬æ•°: $SAMPLE_SIZE"
    echo "  - è®­ç»ƒé›†æ¯”ä¾‹: $TRAIN_RATIO ($(echo "$SAMPLE_SIZE * $TRAIN_RATIO" | bc | cut -d. -f1)æ¡)"
    echo "  - æµ‹è¯•é›†æ¯”ä¾‹: $(echo "1 - $TRAIN_RATIO" | bc) ($(echo "$SAMPLE_SIZE * (1 - $TRAIN_RATIO)" | bc | cut -d. -f1)æ¡)"
    echo "  - é“è·¯è¿è¾“æ¯”ä¾‹: $RAILWAY_RATIO"
    echo ""
    echo "ğŸš€ è®­ç»ƒé…ç½®:"
    echo "  - è®­ç»ƒè½®æ•°: $EPOCHS"
    echo "  - å­¦ä¹ ç‡: $LEARNING_RATE"
    echo "  - æ‰¹æ¬¡å¤§å°: $BATCH_SIZE"
    echo "  - æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: $GRADIENT_ACCUMULATION_STEPS"
    echo "  - æœ€å¤§åºåˆ—é•¿åº¦: $MAX_LENGTH"
    echo ""
    echo "ğŸ“ ç›®å½•é…ç½®:"
    echo "  - æ•°æ®ç›®å½•: $DEBUG_DATA_DIR"
    echo "  - è¾“å‡ºç›®å½•: $DEBUG_OUTPUT_DIR"
    echo "=========================================="
}

# æ£€æŸ¥ç¯å¢ƒ
check_environment() {
    log_step "æ£€æŸ¥è¿è¡Œç¯å¢ƒ..."
    
    # æ£€æŸ¥Python
    if ! command -v python &> /dev/null; then
        log_error "Pythonæœªå®‰è£…"
        exit 1
    fi
    
    # æ£€æŸ¥GPU
    if command -v nvidia-smi &> /dev/null; then
        gpu_info=$(nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits | head -1)
        log_success "ğŸ® GPUå¯ç”¨: $gpu_info"
    else
        log_warning "âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ"
    fi
    
    # æ£€æŸ¥å¿…è¦æ–‡ä»¶
    if [[ ! -f "$PROJECT_DIR/enhanced_data_processor.py" ]]; then
        log_error "æ•°æ®å¤„ç†è„šæœ¬ä¸å­˜åœ¨: $PROJECT_DIR/enhanced_data_processor.py"
        exit 1
    fi
    
    if [[ ! -f "$PROJECT_DIR/train.py" ]]; then
        log_error "è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: $PROJECT_DIR/train.py"
        exit 1
    fi
    
    if [[ ! -f "$PROJECT_DIR/evaluate.py" ]]; then
        log_error "è¯„ä¼°è„šæœ¬ä¸å­˜åœ¨: $PROJECT_DIR/evaluate.py"
        exit 1
    fi
    
    log_success "âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# æ­¥éª¤1: æ•°æ®é¢„å¤„ç†
step_data_preprocessing() {
    log_step "æ­¥éª¤1: æ•°æ®é¢„å¤„ç†"
    echo "=========================================="
    
    # æ¸…ç†æ—§æ•°æ®
    if [[ -d "$DEBUG_DATA_DIR" ]]; then
        log_info "ğŸ§¹ æ¸…ç†æ—§çš„éªŒè¯æ•°æ®..."
        rm -rf "$DEBUG_DATA_DIR"
    fi
    
    # åˆ›å»ºæ•°æ®ç›®å½•
    mkdir -p "$DEBUG_DATA_DIR"
    
    # è¿è¡Œæ•°æ®é¢„å¤„ç†
    log_info "ğŸ”„ ç”ŸæˆéªŒè¯æ•°æ®é›†..."
    cd "$PROJECT_DIR"
    
    python enhanced_data_processor.py \
        --sample_size $SAMPLE_SIZE \
        --train_ratio $TRAIN_RATIO \
        --railway_ratio $RAILWAY_RATIO \
        --output_dir "$DEBUG_DATA_DIR" \
        --random_seed 42
    
    # æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®
    if [[ -f "$DEBUG_DATA_DIR/enhanced_qwen_train.jsonl" ]] && [[ -f "$DEBUG_DATA_DIR/enhanced_qwen_test.jsonl" ]]; then
        train_count=$(wc -l < "$DEBUG_DATA_DIR/enhanced_qwen_train.jsonl")
        test_count=$(wc -l < "$DEBUG_DATA_DIR/enhanced_qwen_test.jsonl")
        train_size=$(du -h "$DEBUG_DATA_DIR/enhanced_qwen_train.jsonl" | cut -f1)
        test_size=$(du -h "$DEBUG_DATA_DIR/enhanced_qwen_test.jsonl" | cut -f1)
        
        log_success "âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ"
        log_info "ğŸ“Š è®­ç»ƒæ•°æ®: $train_count æ¡æ ·æœ¬ ($train_size)"
        log_info "ğŸ“Š æµ‹è¯•æ•°æ®: $test_count æ¡æ ·æœ¬ ($test_size)"
    else
        log_error "âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥"
        exit 1
    fi
}

# æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ
step_model_training() {
    log_step "æ­¥éª¤2: æ¨¡å‹è®­ç»ƒ"
    echo "=========================================="
    
    # æ¸…ç†æ—§çš„è®­ç»ƒè¾“å‡º
    if [[ -d "$DEBUG_OUTPUT_DIR" ]]; then
        log_info "ğŸ§¹ æ¸…ç†æ—§çš„è®­ç»ƒè¾“å‡º..."
        rm -rf "$DEBUG_OUTPUT_DIR"
    fi
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    mkdir -p "$DEBUG_OUTPUT_DIR"
    
    # å¼€å§‹è®­ç»ƒ
    log_info "ğŸš€ å¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒ..."
    cd "$PROJECT_DIR"
    
    python train.py \
        --data_dir "$DEBUG_DATA_DIR" \
        --epochs $EPOCHS \
        --learning_rate $LEARNING_RATE \
        --batch_size $BATCH_SIZE \
        --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
        --max_length $MAX_LENGTH \
        --output_dir "$DEBUG_OUTPUT_DIR" \
        --eval_steps 50 \
        --save_steps 100
    
    # æ£€æŸ¥è®­ç»ƒç»“æœ
    if [[ -f "$DEBUG_OUTPUT_DIR/federated_qwen_model.pth" ]] && [[ -f "$DEBUG_OUTPUT_DIR/training_config.json" ]]; then
        model_size=$(du -h "$DEBUG_OUTPUT_DIR/federated_qwen_model.pth" | cut -f1)
        log_success "âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ"
        log_info "ğŸ¤– æ¨¡å‹æ–‡ä»¶å¤§å°: $model_size"
        
        # æ˜¾ç¤ºè®­ç»ƒé…ç½®
        if [[ -f "$DEBUG_OUTPUT_DIR/training_config.json" ]]; then
            log_info "ğŸ“‹ è®­ç»ƒç»Ÿè®¡:"
            python -c "
import json
with open('$DEBUG_OUTPUT_DIR/training_config.json', 'r') as f:
    config = json.load(f)
print(f\"  - æœ‰æ•ˆè®­ç»ƒæ­¥éª¤: {config.get('valid_steps', 0)}\")
print(f\"  - æœ€ç»ˆå¹³å‡æŸå¤±: {config.get('avg_loss', 0):.4f}\")
print(f\"  - æ€»æŸå¤±: {config.get('total_loss', 0):.4f}\")
"
        fi
    else
        log_error "âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥"
        exit 1
    fi
}

# æ­¥éª¤3: æ¨¡å‹è¯„ä¼°
step_model_evaluation() {
    log_step "æ­¥éª¤3: æ¨¡å‹è¯„ä¼°"
    echo "=========================================="
    
    # è¿è¡Œæ¨¡å‹è¯„ä¼°
    log_info "ğŸ§ª å¼€å§‹æ¨¡å‹è¯„ä¼°..."
    cd "$PROJECT_DIR"
    
    python evaluate.py \
        --model_path "/root/autodl-tmp/Federated_learning/llm_init_ckpt/Qwen2.5-0.5B-Instruct" \
        --checkpoint_path "$DEBUG_OUTPUT_DIR/federated_qwen_model.pth" \
        --test_data "$DEBUG_DATA_DIR/enhanced_qwen_test.jsonl" \
        --max_samples 20 \
        --max_new_tokens 150 \
        --temperature 0.3 \
        --output_file "$DEBUG_OUTPUT_DIR/evaluation_results.json" \
        --device "cuda"
    
    # æ£€æŸ¥è¯„ä¼°ç»“æœ
    if [[ -f "$DEBUG_OUTPUT_DIR/evaluation_results.json" ]]; then
        eval_size=$(du -h "$DEBUG_OUTPUT_DIR/evaluation_results.json" | cut -f1)
        log_success "âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ"
        log_info "ğŸ“Š è¯„ä¼°ç»“æœæ–‡ä»¶: $eval_size"
        
        # æ˜¾ç¤ºå…³é”®è¯„ä¼°æŒ‡æ ‡
        log_info "ğŸ“ˆ å…³é”®è¯„ä¼°æŒ‡æ ‡:"
        python -c "
import json
with open('$DEBUG_OUTPUT_DIR/evaluation_results.json', 'r') as f:
    results = json.load(f)
print(f\"  - ç”ŸæˆæˆåŠŸç‡: {results.get('generation_success_rate', 0)*100:.1f}%\")
print(f\"  - è¿è¾“æ–¹å¼å‡†ç¡®ç‡: {results.get('transport_accuracy', 0)*100:.1f}%\")
print(f\"  - ç›®çš„åœ°åŸå¸‚å‡†ç¡®ç‡: {results.get('city_accuracy', 0)*100:.1f}%\")
print(f\"  - ç›®çš„åœ°çœä»½å‡†ç¡®ç‡: {results.get('province_accuracy', 0)*100:.1f}%\")
print(f\"  - å¹³å‡BLEUåˆ†æ•°: {results.get('avg_bleu_score', 0):.4f}\")
print(f\"  - è¯„ä¼°æ ·æœ¬æ•°: {results.get('total_samples', 0)}\")
"
    else
        log_error "âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥"
        exit 1
    fi
}

# æ­¥éª¤4: è¿‡æ‹ŸåˆéªŒè¯
step_overfitting_validation() {
    log_step "æ­¥éª¤4: è¿‡æ‹ŸåˆéªŒè¯"
    echo "=========================================="
    
    log_info "ğŸ” éªŒè¯æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿè¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®..."
    
    # ä½¿ç”¨è®­ç»ƒæ•°æ®è¿›è¡Œè¯„ä¼°ï¼ˆåº”è¯¥æœ‰å¾ˆé«˜çš„å‡†ç¡®ç‡ï¼‰
    python evaluate.py \
        --model_path "/root/autodl-tmp/Federated_learning/llm_init_ckpt/Qwen2.5-0.5B-Instruct" \
        --checkpoint_path "$DEBUG_OUTPUT_DIR/federated_qwen_model.pth" \
        --test_data "$DEBUG_DATA_DIR/enhanced_qwen_train.jsonl" \
        --max_samples 20 \
        --max_new_tokens 150 \
        --temperature 0.1 \
        --output_file "$DEBUG_OUTPUT_DIR/train_evaluation_results.json" \
        --device "cuda"
    
    if [[ -f "$DEBUG_OUTPUT_DIR/train_evaluation_results.json" ]]; then
        log_success "âœ… è¿‡æ‹ŸåˆéªŒè¯å®Œæˆ"
        log_info "ğŸ“ˆ è®­ç»ƒæ•°æ®è¯„ä¼°ç»“æœ:"
        python -c "
import json
with open('$DEBUG_OUTPUT_DIR/train_evaluation_results.json', 'r') as f:
    results = json.load(f)
transport_acc = results.get('transport_accuracy', 0)*100
city_acc = results.get('city_accuracy', 0)*100
province_acc = results.get('province_accuracy', 0)*100
bleu_score = results.get('avg_bleu_score', 0)

print(f\"  - è¿è¾“æ–¹å¼å‡†ç¡®ç‡: {transport_acc:.1f}%\")
print(f\"  - ç›®çš„åœ°åŸå¸‚å‡†ç¡®ç‡: {city_acc:.1f}%\")
print(f\"  - ç›®çš„åœ°çœä»½å‡†ç¡®ç‡: {province_acc:.1f}%\")
print(f\"  - å¹³å‡BLEUåˆ†æ•°: {bleu_score:.4f}\")

# åˆ¤æ–­æ˜¯å¦è¿‡æ‹ŸåˆæˆåŠŸ
if transport_acc > 50 or city_acc > 30 or bleu_score > 0.1:
    print(f\"\\nâœ… æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ è®­ç»ƒæ•°æ®ï¼Œæ¶æ„å®ç°æ­£ç¡®ï¼\")
else:
    print(f\"\\nâš ï¸ æ¨¡å‹å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæˆ–è°ƒæ•´å‚æ•°\")
"
    else
        log_warning "âš ï¸ è¿‡æ‹ŸåˆéªŒè¯å¤±è´¥"
    fi
}

# ç”ŸæˆéªŒè¯æŠ¥å‘Š
generate_validation_report() {
    log_step "ç”ŸæˆéªŒè¯æŠ¥å‘Š"
    echo "=========================================="
    
    report_file="$DEBUG_OUTPUT_DIR/validation_report.md"
    
    cat > "$report_file" << EOF
# è”é‚¦å­¦ä¹ æ¨¡å‹éªŒè¯æŠ¥å‘Š

## éªŒè¯é…ç½®
- **æ•°æ®æ ·æœ¬æ•°**: $SAMPLE_SIZE æ¡
- **è®­ç»ƒé›†**: $(echo "$SAMPLE_SIZE * $TRAIN_RATIO" | bc | cut -d. -f1) æ¡
- **æµ‹è¯•é›†**: $(echo "$SAMPLE_SIZE * (1 - $TRAIN_RATIO)" | bc | cut -d. -f1) æ¡
- **é“è·¯è¿è¾“æ¯”ä¾‹**: $RAILWAY_RATIO
- **è®­ç»ƒè½®æ•°**: $EPOCHS
- **å­¦ä¹ ç‡**: $LEARNING_RATE
- **æ‰¹æ¬¡å¤§å°**: $BATCH_SIZE

## æ–‡ä»¶ç»“æ„
\`\`\`
$DEBUG_OUTPUT_DIR/
â”œâ”€â”€ federated_qwen_model.pth          # è®­ç»ƒåçš„æ¨¡å‹
â”œâ”€â”€ training_config.json              # è®­ç»ƒé…ç½®
â”œâ”€â”€ evaluation_results.json           # æµ‹è¯•é›†è¯„ä¼°ç»“æœ
â”œâ”€â”€ train_evaluation_results.json     # è®­ç»ƒé›†è¯„ä¼°ç»“æœï¼ˆè¿‡æ‹ŸåˆéªŒè¯ï¼‰
â””â”€â”€ validation_report.md              # æœ¬æŠ¥å‘Š
\`\`\`

## éªŒè¯ç»“è®º
EOF

    # æ·»åŠ éªŒè¯ç»“è®º
    if [[ -f "$DEBUG_OUTPUT_DIR/evaluation_results.json" ]] && [[ -f "$DEBUG_OUTPUT_DIR/train_evaluation_results.json" ]]; then
        python >> "$report_file" << 'EOF'
import json

# è¯»å–è¯„ä¼°ç»“æœ
with open('DEBUG_OUTPUT_DIR/evaluation_results.json'.replace('DEBUG_OUTPUT_DIR', 'DEBUG_OUTPUT_DIR_VALUE'), 'r') as f:
    test_results = json.load(f)
with open('DEBUG_OUTPUT_DIR/train_evaluation_results.json'.replace('DEBUG_OUTPUT_DIR', 'DEBUG_OUTPUT_DIR_VALUE'), 'r') as f:
    train_results = json.load(f)

print("\n### æµ‹è¯•é›†è¡¨ç°")
print(f"- ç”ŸæˆæˆåŠŸç‡: {test_results.get('generation_success_rate', 0)*100:.1f}%")
print(f"- è¿è¾“æ–¹å¼å‡†ç¡®ç‡: {test_results.get('transport_accuracy', 0)*100:.1f}%")
print(f"- ç›®çš„åœ°åŸå¸‚å‡†ç¡®ç‡: {test_results.get('city_accuracy', 0)*100:.1f}%")
print(f"- å¹³å‡BLEUåˆ†æ•°: {test_results.get('avg_bleu_score', 0):.4f}")

print("\n### è®­ç»ƒé›†è¡¨ç°ï¼ˆè¿‡æ‹ŸåˆéªŒè¯ï¼‰")
print(f"- è¿è¾“æ–¹å¼å‡†ç¡®ç‡: {train_results.get('transport_accuracy', 0)*100:.1f}%")
print(f"- ç›®çš„åœ°åŸå¸‚å‡†ç¡®ç‡: {train_results.get('city_accuracy', 0)*100:.1f}%")
print(f"- å¹³å‡BLEUåˆ†æ•°: {train_results.get('avg_bleu_score', 0):.4f}")

# éªŒè¯ç»“è®º
train_transport = train_results.get('transport_accuracy', 0)*100
train_city = train_results.get('city_accuracy', 0)*100
train_bleu = train_results.get('avg_bleu_score', 0)

print("\n### æ¶æ„éªŒè¯ç»“è®º")
if train_transport > 50 or train_city > 30 or train_bleu > 0.1:
    print("âœ… **æ¨¡å‹æ¶æ„å®ç°æ­£ç¡®**")
    print("- æ¨¡å‹èƒ½å¤ŸæˆåŠŸå­¦ä¹ è®­ç»ƒæ•°æ®")
    print("- Split Learningæ¶æ„å·¥ä½œæ­£å¸¸")
    print("- è”é‚¦æƒé‡åŒæ­¥æœºåˆ¶æœ‰æ•ˆ")
    print("- SFTæŸå¤±è®¡ç®—æ­£ç¡®")
else:
    print("âš ï¸ **éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•**")
    print("- æ¨¡å‹å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒè½®æ•°")
    print("- å­¦ä¹ ç‡å¯èƒ½éœ€è¦è°ƒæ•´")
    print("- æ•°æ®è´¨é‡å¯èƒ½éœ€è¦æ”¹è¿›")
EOF
        # æ›¿æ¢å ä½ç¬¦
        sed -i "s/DEBUG_OUTPUT_DIR_VALUE/$DEBUG_OUTPUT_DIR/g" "$report_file"
    fi
    
    log_success "âœ… éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# æ¸…ç†å‡½æ•°
cleanup() {
    log_info "ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ¸…ç†é€»è¾‘
}

# ä¸»å‡½æ•°
main() {
    echo -e "${GREEN}ğŸš€ å¼€å§‹è”é‚¦å­¦ä¹ æ¨¡å‹å®Œæ•´éªŒè¯${NC}"
    echo "=========================================="
    
    # æ˜¾ç¤ºé…ç½®
    show_config
    echo ""
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_environment
    echo ""
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time=$(date +%s)
    
    # æ‰§è¡ŒéªŒè¯æ­¥éª¤
    step_data_preprocessing
    echo ""
    
    step_model_training
    echo ""
    
    step_model_evaluation
    echo ""
    
    step_overfitting_validation
    echo ""
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_validation_report
    echo ""
    
    # è®¡ç®—æ€»è€—æ—¶
    end_time=$(date +%s)
    duration=$((end_time - start_time))
    minutes=$((duration / 60))
    seconds=$((duration % 60))
    
    # æœ€ç»ˆæ€»ç»“
    echo "=========================================="
    log_success "ğŸ‰ è”é‚¦å­¦ä¹ æ¨¡å‹éªŒè¯å®Œæˆï¼"
    log_info "â±ï¸ æ€»è€—æ—¶: ${minutes}åˆ†${seconds}ç§’"
    log_info "ğŸ“ ç»“æœç›®å½•: $DEBUG_OUTPUT_DIR"
    log_info "ğŸ“‹ éªŒè¯æŠ¥å‘Š: $DEBUG_OUTPUT_DIR/validation_report.md"
    echo ""
    
    log_info "ğŸ” æŸ¥çœ‹éªŒè¯æŠ¥å‘Š:"
    log_info "   cat \"$DEBUG_OUTPUT_DIR/validation_report.md\""
    echo ""
    
    log_info "ğŸ“Š æŸ¥çœ‹è¯¦ç»†è¯„ä¼°ç»“æœ:"
    log_info "   cat \"$DEBUG_OUTPUT_DIR/evaluation_results.json\""
    echo "=========================================="
}

# æ•è·é€€å‡ºä¿¡å·è¿›è¡Œæ¸…ç†
trap cleanup EXIT

# è¿è¡Œä¸»å‡½æ•°
main "$@"
