#!/bin/bash

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# è„šæœ¬é…ç½®
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
ABLATION_CONFIG="$SCRIPT_DIR/ablation_configs.yaml"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

log_header() {
    echo -e "${PURPLE}[ABLATION]${NC} $1"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
æ¶ˆèå®éªŒå¯åŠ¨è„šæœ¬

ç”¨æ³•: $0 [é€‰é¡¹]

é€‰é¡¹:
    --experiment EXPERIMENT     è¿è¡ŒæŒ‡å®šçš„å®éªŒ (baseline|no_port|no_railway|no_customs|all)
    --epochs EPOCHS            è®­ç»ƒè½®æ•° (é»˜è®¤: 3)
    --learning-rate LR          å­¦ä¹ ç‡ (é»˜è®¤: 2e-6)
    --batch-size SIZE          æ‰¹æ¬¡å¤§å° (é»˜è®¤: 4)
    --max-samples SAMPLES      æœ€å¤§æ ·æœ¬æ•° (é»˜è®¤: 4000)
    --output-dir DIR           è¾“å‡ºç›®å½• (é»˜è®¤: ablation_experiments)
    --skip-data-generation     è·³è¿‡æ•°æ®ç”Ÿæˆæ­¥éª¤
    --dry-run                  åªæ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„å‘½ä»¤ï¼Œä¸å®é™…è¿è¡Œ
    --help                     æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

å®éªŒç±»å‹:
    baseline    - å®Œæ•´è”é‚¦å­¦ä¹ ï¼ˆæ¸¯å£+é“è·¯+æµ·å…³ï¼‰
    no_port     - å»é™¤æ¸¯å£å®¢æˆ·ç«¯ï¼ˆé“è·¯+æµ·å…³ï¼‰
    no_railway  - å»é™¤é“è·¯å®¢æˆ·ç«¯ï¼ˆæ¸¯å£+æµ·å…³ï¼‰
    no_customs  - å»é™¤æµ·å…³å®¢æˆ·ç«¯ï¼ˆæ¸¯å£+é“è·¯ï¼‰
    all         - è¿è¡Œæ‰€æœ‰å®éªŒï¼ˆé»˜è®¤ï¼‰

ç¤ºä¾‹:
    $0                                      # è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ
    $0 --experiment baseline               # åªè¿è¡ŒåŸºå‡†å®éªŒ
    $0 --experiment no_port --epochs 5    # è¿è¡Œå»é™¤æ¸¯å£çš„å®éªŒï¼Œ5ä¸ªepoch
    $0 --dry-run                          # é¢„è§ˆæ‰€æœ‰å°†è¦æ‰§è¡Œçš„å‘½ä»¤

EOF
}

# é»˜è®¤å‚æ•°
EXPERIMENT="all"
EPOCHS=3
LEARNING_RATE="2e-6"
BATCH_SIZE=4
MAX_SAMPLES=4000
OUTPUT_DIR="ablation_experiments"
SKIP_DATA_GEN=false
DRY_RUN=false

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        --experiment)
            EXPERIMENT="$2"
            shift 2
            ;;
        --epochs)
            EPOCHS="$2"
            shift 2
            ;;
        --learning-rate)
            LEARNING_RATE="$2"
            shift 2
            ;;
        --batch-size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --max-samples)
            MAX_SAMPLES="$2"
            shift 2
            ;;
        --output-dir)
            OUTPUT_DIR="$2"
            shift 2
            ;;
        --skip-data-generation)
            SKIP_DATA_GEN=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --help)
            show_help
            exit 0
            ;;
        *)
            log_error "æœªçŸ¥å‚æ•°: $1"
            show_help
            exit 1
            ;;
    esac
done

# éªŒè¯å®éªŒç±»å‹
if [[ ! "$EXPERIMENT" =~ ^(baseline|no_port|no_railway|no_customs|all)$ ]]; then
    log_error "æ— æ•ˆçš„å®éªŒç±»å‹: $EXPERIMENT"
    show_help
    exit 1
fi

# ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­
cd "$PROJECT_ROOT"

# åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
create_output_structure() {
    local base_dir="$1"
    log_info "åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„: $base_dir"
    
    if [[ "$DRY_RUN" == "false" ]]; then
        mkdir -p "$base_dir"/{data,models,logs,results,reports}
    else
        log_info "[DRY RUN] mkdir -p $base_dir/{data,models,logs,results,reports}"
    fi
}

# ç”Ÿæˆæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
generate_data() {
    local clients="$1"
    local suffix="$2"
    
    if [[ "$SKIP_DATA_GEN" == "true" ]]; then
        log_info "è·³è¿‡æ•°æ®ç”Ÿæˆæ­¥éª¤"
        return 0
    fi
    
    log_info "ä¸ºå®éªŒ $suffix ç”Ÿæˆæ•°æ®..."
    
    local data_output_dir="$OUTPUT_DIR/data/$suffix"
    local cmd="python enhanced_data_processor.py \
        --data_dir \"/root/autodl-tmp/Federated_learning/code_v01/verify_data\" \
        --output_dir \"$data_output_dir\" \
        --sample_size $MAX_SAMPLES \
        --railway_ratio 0.6 \
        --random_seed 42"
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log_info "[DRY RUN] $cmd"
    else
        if ! eval "$cmd"; then
            log_error "æ•°æ®ç”Ÿæˆå¤±è´¥: $suffix"
            return 1
        fi
        log_success "æ•°æ®ç”Ÿæˆå®Œæˆ: $suffix"
    fi
}

# è¿è¡Œè®­ç»ƒ
run_training() {
    local clients="$1"
    local suffix="$2"
    local exp_name="$3"
    
    log_header "å¼€å§‹è®­ç»ƒå®éªŒ: $exp_name"
    
    local data_dir="$OUTPUT_DIR/data/$suffix"
    local model_output="$OUTPUT_DIR/models/$suffix"
    local log_file="$OUTPUT_DIR/logs/train_$suffix.log"
    
    # æ„å»ºå®¢æˆ·ç«¯å‚æ•°
    local client_args=""
    IFS=',' read -ra CLIENT_ARRAY <<< "$clients"
    for client in "${CLIENT_ARRAY[@]}"; do
        client_args="$client_args --enabled_clients $client"
    done
    
    local cmd="python train.py \
        --data_dir \"$data_dir\" \
        --output_dir \"$model_output\" \
        --epochs $EPOCHS \
        --learning_rate $LEARNING_RATE \
        --batch_size $BATCH_SIZE \
        --max_samples $MAX_SAMPLES \
        $client_args \
        2>&1 | tee \"$log_file\""
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log_info "[DRY RUN] $cmd"
    else
        if ! eval "$cmd"; then
            log_error "è®­ç»ƒå¤±è´¥: $exp_name"
            return 1
        fi
        log_success "è®­ç»ƒå®Œæˆ: $exp_name"
    fi
}

# è¿è¡Œè¯„ä¼°
run_evaluation() {
    local clients="$1"
    local suffix="$2"
    local exp_name="$3"
    
    log_header "å¼€å§‹è¯„ä¼°å®éªŒ: $exp_name"
    
    local data_dir="$OUTPUT_DIR/data/$suffix"
    local model_path="$OUTPUT_DIR/models/$suffix/federated_qwen_model.pth"
    local result_file="$OUTPUT_DIR/results/eval_$suffix.json"
    local log_file="$OUTPUT_DIR/logs/eval_$suffix.log"
    
    local cmd="python evaluate.py \
        --checkpoint_path \"$model_path\" \
        --test_data \"$data_dir/enhanced_qwen_test.jsonl\" \
        --max_samples 1000 \
        --output_file \"$result_file\" \
        2>&1 | tee \"$log_file\""
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log_info "[DRY RUN] $cmd"
    else
        if ! eval "$cmd"; then
            log_error "è¯„ä¼°å¤±è´¥: $exp_name"
            return 1
        fi
        log_success "è¯„ä¼°å®Œæˆ: $exp_name"
    fi
}

# è¿è¡Œå•ä¸ªå®éªŒ
run_single_experiment() {
    local exp_type="$1"
    
    local clients=""
    local suffix=""
    local name=""
    
    case $exp_type in
        "baseline")
            clients="port,railway,customs"
            suffix="baseline_all_clients"
            name="å®Œæ•´è”é‚¦å­¦ä¹ ï¼ˆæ¸¯å£+é“è·¯+æµ·å…³ï¼‰"
            ;;
        "no_port")
            clients="railway,customs"
            suffix="ablation_no_port"
            name="å»é™¤æ¸¯å£å®¢æˆ·ç«¯ï¼ˆé“è·¯+æµ·å…³ï¼‰"
            ;;
        "no_railway")
            clients="port,customs"
            suffix="ablation_no_railway"
            name="å»é™¤é“è·¯å®¢æˆ·ç«¯ï¼ˆæ¸¯å£+æµ·å…³ï¼‰"
            ;;
        "no_customs")
            clients="port,railway"
            suffix="ablation_no_customs"
            name="å»é™¤æµ·å…³å®¢æˆ·ç«¯ï¼ˆæ¸¯å£+é“è·¯ï¼‰"
            ;;
        *)
            log_error "æœªçŸ¥å®éªŒç±»å‹: $exp_type"
            return 1
            ;;
    esac
    
    log_header "=========================================="
    log_header "å®éªŒ: $name"
    log_header "å®¢æˆ·ç«¯: $clients"
    log_header "è¾“å‡ºåç¼€: $suffix"
    log_header "=========================================="
    
    # ç”Ÿæˆæ•°æ®
    generate_data "$clients" "$suffix" || return 1
    
    # è®­ç»ƒ
    run_training "$clients" "$suffix" "$name" || return 1
    
    # è¯„ä¼°
    run_evaluation "$clients" "$suffix" "$name" || return 1
    
    log_success "å®éªŒå®Œæˆ: $name"
    echo ""
}

# ä¸»å‡½æ•°
main() {
    log_header "ğŸ§ª å¼€å§‹æ¶ˆèå®éªŒ..."
    echo "=========================================="
    log_info "å®éªŒé…ç½®:"
    log_info "  - å®éªŒç±»å‹: $EXPERIMENT"
    log_info "  - è®­ç»ƒè½®æ•°: $EPOCHS"
    log_info "  - å­¦ä¹ ç‡: $LEARNING_RATE"
    log_info "  - æ‰¹æ¬¡å¤§å°: $BATCH_SIZE"
    log_info "  - æœ€å¤§æ ·æœ¬æ•°: $MAX_SAMPLES"
    log_info "  - è¾“å‡ºç›®å½•: $OUTPUT_DIR"
    log_info "  - è·³è¿‡æ•°æ®ç”Ÿæˆ: $SKIP_DATA_GEN"
    log_info "  - è¯•è¿è¡Œæ¨¡å¼: $DRY_RUN"
    echo "=========================================="
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    create_output_structure "$OUTPUT_DIR"
    
    # è®°å½•å®éªŒå¼€å§‹æ—¶é—´
    start_time=$(date)
    log_info "å®éªŒå¼€å§‹æ—¶é—´: $start_time"
    
    # è¿è¡Œå®éªŒ
    if [[ "$EXPERIMENT" == "all" ]]; then
        log_header "è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ..."
        run_single_experiment "baseline" || exit 1
        run_single_experiment "no_port" || exit 1
        run_single_experiment "no_railway" || exit 1
        run_single_experiment "no_customs" || exit 1
    else
        run_single_experiment "$EXPERIMENT" || exit 1
    fi
    
    # è®°å½•å®éªŒç»“æŸæ—¶é—´
    end_time=$(date)
    log_success "å®éªŒç»“æŸæ—¶é—´: $end_time"
    
    # ç”Ÿæˆå®éªŒæŠ¥å‘Š
    if [[ "$DRY_RUN" == "false" && "$EXPERIMENT" == "all" ]]; then
        log_header "ç”Ÿæˆæ¶ˆèå®éªŒæŠ¥å‘Š..."
        bash "$SCRIPT_DIR/generate_ablation_report.sh" --input_dir "$OUTPUT_DIR" --output_file "$OUTPUT_DIR/reports/ablation_analysis.md"
    fi
    
    log_success "ğŸ‰ æ‰€æœ‰æ¶ˆèå®éªŒå®Œæˆ!"
    log_info "ç»“æœä¿å­˜åœ¨: $OUTPUT_DIR"
}

# æ£€æŸ¥å¿…è¦æ–‡ä»¶å’Œä¾èµ–
check_dependencies() {
    local missing_files=()
    
    if [[ ! -f "enhanced_data_processor.py" ]]; then
        missing_files+=("enhanced_data_processor.py")
    fi
    
    if [[ ! -f "train.py" ]]; then
        missing_files+=("train.py")
    fi
    
    if [[ ! -f "evaluate.py" ]]; then
        missing_files+=("evaluate.py")
    fi
    
    if [[ ${#missing_files[@]} -gt 0 ]]; then
        log_error "ç¼ºå°‘å¿…è¦æ–‡ä»¶:"
        for file in "${missing_files[@]}"; do
            log_error "  - $file"
        done
        exit 1
    fi
}

# æ‰§è¡Œä¸»å‡½æ•°
check_dependencies
main

log_info "æ¶ˆèå®éªŒè„šæœ¬æ‰§è¡Œå®Œæˆã€‚"
